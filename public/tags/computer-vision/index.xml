<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Computer Vision on Sandra Tang</title>
    <link>http://localhost:1313/tags/computer-vision/</link>
    <description>Recent content in Computer Vision on Sandra Tang</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <managingEditor>st2232@cornell.edu (Sandra Tang)</managingEditor>
    <webMaster>st2232@cornell.edu (Sandra Tang)</webMaster>
    <copyright>Â© 2025 Sandra Tang</copyright>
    <atom:link href="http://localhost:1313/tags/computer-vision/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Handwriting Recognition Web App</title>
      <link>http://localhost:1313/docs/installation/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <author>st2232@cornell.edu (Sandra Tang)</author>
      <guid>http://localhost:1313/docs/installation/</guid>
      <description>&lt;h2 class=&#34;relative group&#34;&gt;Overview 
    &lt;div id=&#34;overview&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#overview&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;div class=&#34;lead text-neutral-500 dark:text-neutral-400 !mb-9 text-xl&#34;&gt;
  An end-to-end handwriting recognition system with a dynamic Javascript-based front-end and a classification model backend using Flask that takes in handwritten images and converts it to text.
&lt;/div&gt;


&lt;h2 class=&#34;relative group&#34;&gt;Model Architecture 
    &lt;div id=&#34;model-architecture&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#model-architecture&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;p&gt;The model is a CRNN (Convolutional Recurrent Neural Network) trained with CTC (Connectionist Temporal Classification) loss, allowing it to recognize sequences of characters from variable-length handwritten inputs without needing explicit alignment between input and labels.&lt;/p&gt;</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:1313/docs/installation/featured.png" />
    </item>
    
    <item>
      <title>Video Classification Model for Mice Responses to Dynamic Stimuli</title>
      <link>http://localhost:1313/docs/getting-started/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <author>st2232@cornell.edu (Sandra Tang)</author>
      <guid>http://localhost:1313/docs/getting-started/</guid>
      <description>&lt;h2 class=&#34;relative group&#34;&gt;Overview 
    &lt;div id=&#34;overview&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#overview&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;div class=&#34;lead text-neutral-500 dark:text-neutral-400 !mb-9 text-xl&#34;&gt;
  A deep learning model leveraging ViViT and qLoRA to predict neuronal firing patterns in mice based on dynamic video stimuli.
&lt;/div&gt;

&lt;p&gt;This research project builds a machine learning pipeline for decoding murine neural activity from naturalistic video input. The core of the system is a fine-tuned Video Vision Transformer (ViViT) that has been adapted to learn temporal and spatial patterns associated with neural responses.&lt;/p&gt;</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:1313/docs/getting-started/featured.png" />
    </item>
    
  </channel>
</rss>
